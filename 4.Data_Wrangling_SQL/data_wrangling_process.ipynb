{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map Area:** Brooklyn (Kings County) in New York City, and surrounding neighborhoods including Southwest Queens and Far Rockaway, Lower Manhattan, and part of the New Jersey coastline bordering Manhattan.\n",
    "I chose this area since it is where I reside.\n",
    "\n",
    "[Link to extract](https://mapzen.com/data/metro-extracts/metro/brooklyn_new-york/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems in the Dataset**\n",
    "\n",
    "After downloading the file in xml format, I ran procedures in the ElementTree module to find the following problems with the data set:\n",
    "\n",
    "(1) Use of street abbreviations, for example \"St.\" or \"Ave\" in place of \"Street\" or \"Avenue\".\n",
    "\n",
    "(2) Inconsistent residential formatting: instances where an apartment unit number was included within the street address tag, rather than receiving its own entry/ key-value tag.\n",
    "\n",
    "(3) Inconsistent commercial formatting: overlap and ambiguity when using the \"amenity\" or \"shop\" key for certain industries.\n",
    "\n",
    "(4) Invalid formatting of house number tags. Some of these tags were not actually numbers but more general address specifications.\n",
    "\n",
    "(5) Inconsistency in Zip code format (ex. \"10002\" vs \"10002-1013\" vs \"NY 10002\")\n",
    "\n",
    "(6) City names either missing, inconsistent in content (ex. \"Brooklyn, NY\" vs \"Brooklyn\") or inconsistent in format. In the later case, an address in Kings Country, for example, could be tagged under \"Brooklyn\" or \"New York City\" depending upon the concept or popular usage of \"city\".\n",
    "\n",
    "(7) Incorrect zip code and city formatting. This is an extension of (6). Since city tags were geographically inconsistent, the relation between zip codes and cities is also ambiguous. A zip code-city mapping should be implemented such that, whenever possible, each zip code refers to only one city.\n",
    "After analyzing the data to find these problems, I wrote functions to clean the data in audit.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SQL Database**\n",
    "\n",
    "The cleaned data was then exported into a SQL database so it could be queried more efficiently. For example, the number of unique nodes, ways, and users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-2-b873332aa1e1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b873332aa1e1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    '''SELECT COUNT(*)FROM nodes;''''\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\n",
    "'''SELECT COUNT(*)FROM nodes;''''\n",
    ")\n",
    "           cursor.execute ('''\n",
    "           SELECT COUNT (*) FROM ways;'''\n",
    "           )\n",
    "           cursor.execute('''SELECT COUNT(DISTINCT(user.uid))\n",
    "           FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) as user;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 2,495,350 nodes; 492,780 ways, and 1,645 unique users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems in the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Inconsistent Street Abbreviations**\n",
    "\n",
    "By using regular expressions to parse through the data, I found the most common street abbreviations (those used more than twice) were:\n",
    "\n",
    "'St': 104,<br>\n",
    "'Ave': 26, <br>\n",
    "'St.': 16,<br>\n",
    "'Blvd': 12,\n",
    "\n",
    "\n",
    "In addition, grammatical inconsistencies were present in non-abbreviated street types (ex. '70th Avenue,' , 'Bedford avenue') and in abbreviated street type ('South 4th st', 'Schermerhorn St.') Finally, there were a few instances of obvious misspellings such as 'Nostrand Avene' or 'West 8th Steet'.\n",
    "To correct these tags, I compiled all abbreviations, grammatical inconsistencies, and spelling mistakes into a dictionary and mapped each key to its corrected form. This dictionary, named \"streetmapping\" is detailed below:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streetmapping = {\n",
    "\"Ave\" : \"Avenue\",\n",
    "\"Ave.\" : \"Avenue\",\n",
    "\"Avene\" : \"Avenue\",\n",
    "\"Avenue,\" : \"Avenue\",\n",
    "\"avenue\" : \"Avenue\",\n",
    "\"ave\": \"Avenue\",\n",
    "\"brway\":\"Broadway\",\n",
    "\"Blvd\" :\"Boulevard\",\n",
    "\"Ctr\": \"Center\",\n",
    "\"Dr\":\"Drive\",\n",
    "\"Plz\" : \"Plaza\",\n",
    "\"Rd\" : \"Road\",\n",
    "\"ST\" : \"Street\",\n",
    "'St': \"Street\",\n",
    "'St.' : \"Street\",\n",
    " \"St.,\" : \"Street\",\n",
    "'Steet' : \"Street\",\n",
    "'st' : \"Street\",\n",
    "'street' : \"Street\",\n",
    "\"Street,\":\"Street\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Unit or Apartment Address Included Within Street Address**\n",
    "\n",
    "In most of the dataset, unit/apartment numbers are tagged separately. In some instances, however, these designations are appended to the street address. For example, the code bolded below:\n",
    "\n",
    "{'website': 'http://adlervermillion.com (http://adlervermillion.com)', 'payment:bitcoin': 'yes', 'name': 'Adler, Vermillion & Skocilich LLP', 'addr:postcode': '11201', 'addr:housename': 'Adler, Vermillion & Skocilich LLP', 'addr:city': 'Brooklyn', 'addr:housenumber': '45', **'addr:street': 'Main St., Suite 500'**}\n",
    "\n",
    "\n",
    "Addresses formatted like the above do not recognize the integrity of each piece of information specifying a given address. In the above example, just as house number 45 receives its own key-value tag, so should \"Suite 500\".\n",
    "\n",
    "\n",
    "To find these discrepancies, I again used regular expressions to search street names ending in numbers. I compiled all the element tags of these street names into a dictionary to get a closer look.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "def audit (osmfile):\n",
    "'''Searches for elements with streetnames that end in a string containing a number,\n",
    "    and stores all tags for these elements in a list.'''\n",
    "\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    problemlist = []\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\": \n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib[\"k\"] == \"addr:street\":\n",
    "                    street_name = tag.attrib[\"v\"]\n",
    "                    street_endings = street_type_re.search(street_name)\n",
    "                    street_endings = street_endings.group() \n",
    "                    numerical_street_endings = re.search(r'\\d', street_endings)\n",
    "                    \n",
    "                    if numerical_street_endings:\n",
    "                        numberstreets = {}\n",
    "                        for tag in elem.iter(\"tag\"):\n",
    "                            numberstreets[tag.attrib[\"k\"]] = tag.attrib[\"v\"]\n",
    "                        problemlist.append(numberstreets)   \n",
    "                            \n",
    "                           \n",
    "    return problemlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all these cases, where a unit or apartment number was given within the street address, this number was listed immediately after the street type or street type abbreviation already stored within the streetmapping dictionary created above in (1). I was therefore able to use the occurrence of the street type (ex. \"St.\") to split the string into a substring specifying the street address (\"Main St.\") and a substring specifying the unit (\"Suite 500\"). I could then create a new tag (\"Unit\":\"Suite 500\") to store this information separately from the address. (Of course, in this case \"Main St\" would also need to be amended to \"Main Street\" as detailed in (1) above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 Commercial Tagging**\n",
    "\n",
    "In the Openstreetmap project, business are tagged under the \"shop\" or \"amenity\" key. However, because this schema is somewhat ambiguous, certain services/products are tagged under both types of keys depending upon the user. These overlapping cases are detailed below:\n",
    "\n",
    "'funeral_directors':{'amenity tags': 1, 'shops tags': 1}, <br>\n",
    "'laundry': {'amenity tags': 1, 'shops tags': 46}, <br>\n",
    "'ice_cream': {'amenity tags': 9, 'shops tags': 2}\n",
    "\n",
    "I corrected for this by amending \"laundry\" and \"ice_cream\" to be tagged under the shop key. In general, the \"shop\" tag seems to be a narrower or more specific concept better suited for these types of businesses. The amenity tag is broader category that includes more generally useful places such as \"parking space\" \"marketspace\" and \"pharmacy\".\n",
    "\n",
    "However, because this schema is quite ambiguous, I would recommend replacing it with a more precise schema employing the categories \"commercial\" or \"public\" rather than the \"shop\" or \"amenity\" designation.\n",
    "\n",
    "For example, once the data was clearned and exported to an SQL data base, I ran the following query in the terminal to find the most commonly tagged amenities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute ('''SELECT COUNT(*) as count\n",
    "FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) as tags\n",
    "WHERE tags.key = \"amenity\";''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supermarket,185<br>\n",
    "clothes,156<br>\n",
    "convenience,115 <br>\n",
    "bakery,58 <br>\n",
    "hairdresser,57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However while this public/private schema is a more precise and perhaps more intutive way of classifying addresses, it may also introduce new ambiguities into the dataset.\n",
    "\n",
    "For example, depending upon the user, a non-profift facility such as a YMCA gym might be classified as either \"public\" or \"commercial.\" The same problems pertain to such non-profit ventures such as Planned Parenthood and Goodwill, or even entire institutiosn such as hospitals or hospices.\n",
    "\n",
    "Lastly, there were also some \"shop\" tags missing names. Running the query below for the total number of shops returns 1375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " cursor.execute ('''SELECT COUNT(*) as count\n",
    "FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) as tag s\n",
    "WHERE tags.key = \"shop\";''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But performing an inner join and running a query for the total number of shops that also have a \"name\" value returns 974 and 253 respectively for nodes and ways. The percentage then of shops missing a name is about 11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute ('''SELECT COUNT (*) as count\n",
    "FROM nodes_tags as n1, nodes_tags as n2\n",
    "WHERE (n1.key = \"name\" and n2.key = \"shop\") and n1.id = n2.id;''')\n",
    "#Returns 974\n",
    "\n",
    "cursor.execute ('''SELECT COUNT (*) as count\n",
    "FROM ways_tags as w1, ways_tags as w2\n",
    "WHERE (w1.key = \"name\" and w2.key = \"shop\") and w1.id = w2.id;''')\n",
    "#Returns 253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Housenumbers**\n",
    "\n",
    "The code below runs a check that each value under \"addr:housenumber\" does contains a number of some sort, for example (\"5B\" or \"5 1/2\" would be permissible). Like before, the tags for elements failing this test are are compiled within a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "def parsehousenumbers (osmfile):\n",
    "    problemlist = []\n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\": \n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib[\"k\"] == \"addr:housenumber\": housenumber = tag.attrib[\"v\"]\n",
    "                if not is_number (housenumber):\n",
    "                    nonnumerical = {}\n",
    "                    for tag in elem.iter(\"tag\"):\n",
    "                        nonnumerical[tag.attrib[\"k\"]] = tag.attrib [\"v\"]\n",
    "                    problemlist.append(nonnumerical)\n",
    "    return problemlist\n",
    "\n",
    "def is_number(s):\n",
    "    '''http://stackoverflow.com/questions/31083503/how-do-i-check-if-a-s\n",
    "           tring-contains-any-numbers'''\n",
    "    if any(str.isdigit(c) for c in s): \n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases, where an element failed this test, the housenumber tag was used more generally as an address specification. For example, the code below. In these cases, I corrected the \"addr:housenumber\" tag to a more general \"addr:note\" key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example =[\n",
    "{'addr:city': 'Forest Hills',\n",
    "  'addr:housenumber': 'South side of Queens Blvd at',\n",
    "  'addr:postcode': '11375',\n",
    "  'addr:street': '70th Avenue,',\n",
    "  'area': 'yes',\n",
    "  'name': 'Forest Hills Greenmarket',\n",
    "  'note': '-Open Sundays, Year Round :) -Market Hours: 8:00 a.m. - 3:00 p.m. -Compost Collection w/ BIG!\\\n",
    "  Compost:10am-12pm -EBT/Food Stamps, Debit/Credit, and WIC & FMNP Coupons accepted 8:30am-2pm',\n",
    "  'website': 'http://www.grownyc.org/greenmarket/queens/forest-hills'},\n",
    " {'addr:city': 'Forest Hills',\n",
    "  'addr:housenumber': 'Deepdene Road and Underwood Road',\n",
    "  'leisure': 'park',\n",
    "  'name': 'Deepdene Park',\n",
    "  'note': 'Great sledding in the WInter & firefly catching in warmer months! :)'\n",
    " }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Zipcodes**\n",
    "\n",
    "Zipcodes were formatted inconsistently throughout the dataset which I discovered running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-c80b0e847d72>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-c80b0e847d72>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import xml.etree.cElementTree as ET from collections import defaultdict\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET \n",
    "from collections import defaultdict\n",
    "\n",
    "def audit (osmfile):\n",
    "'''Returns a dictionary of zipcodes used within the dataset and the number of times each zipcode is used.'''\n",
    "    zipcodedict = defaultdict(int)\n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib[\"k\"] == \"addr:postcode\":\n",
    "                    zipcodedict[tag.attrib[\"v\"]] +=1\n",
    "    return zipcodedict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of zip codes were formatted using a 5 number only system. Exceptions, for example, were 'NY 11201' (used twice) and '11201-2483' (used just once) to '11201' which was used in 3,895 tags. I corrected the data by using regular expressions to delete non-numerical characters and then splicing the string to get only the first five numbers. The third line of the string replaces zip code \"10048\" with \"10007\". The \"10048\" zip code was assigned to the original World Trade Center complex, and discontinued following the September 11 attacks in 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def correctzip (s):\n",
    "    s = re.sub(\"\\D\", \"\", s) \n",
    "    s = s[0:5]\n",
    "    if s == \"10048\":\n",
    "        s = \"10007\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Cities**\n",
    "Cities are used inconsistently throughout the dataset. For example, running the code below returns instances of all of the following number of tags under \"addr:city\":\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Brookklyn': 20,\n",
       " 'Brooklyn': 1747,\n",
       " 'Brooklyn ': 2,\n",
       " 'Brooklyn, NY': 5,\n",
       " 'Brooklyn, New York': 1,\n",
       " 'brooklyn': 7}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Brookklyn': 20,\n",
    " 'Brooklyn': 1747,\n",
    " 'Brooklyn ': 2,\n",
    " 'Brooklyn, NY': 5,\n",
    " 'Brooklyn, New York': 1,\n",
    " 'brooklyn': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def citiescount (osmfile):\n",
    "    citydict = defaultdict(int)\n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib[\"k\"] == \"addr:city\":\n",
    "                    citydict[tag.attrib[\"v\"]] +=1\n",
    "    return citydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full mapping of the code to correct all grammatical inconsistencies in the dataset is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_mapping = {\n",
    "\"Brookklyn\": \"Brooklyn\",\n",
    "\"brooklyn\": \"Brooklyn\",\n",
    "\"Brooklyn, NY\": \"Brooklyn\",\n",
    "\"Brooklyn, New York\": \"Brooklyn\",\n",
    "\"Brooklyn \": \"Brooklyn\",\n",
    " \"M\": \"New York\",\n",
    "\"Manhattan NYC\": \"New York\",\n",
    "\"NEW YORK CITY\": \"New York\",\n",
    "\"New York CIty\": \"New York\",\n",
    "\"New York City\": \"New York\",\n",
    "\"New York, NY\": \"New York\",\n",
    "\"Tribeca\": \"New York\",\n",
    "\"York City\": \"New York\",\n",
    "\"new york\": \"New York\",\n",
    "\"Glendale, NY\":\"Glendale\",\n",
    "\"Ozone Park, NY\": \"Ozone Park\",\n",
    "\"queens\": \"Queens\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More interesting, however, than the misspellings or inconsistencies within a single city name such as \"Brooklyn\" is that the very category of a city is applied differently throughout the data. An address in Kings County, for example, was sometimes tagged under the city of \"Brooklyn\" - referring to its autonomous borough status, and sometimes tagged as \"New York\" - referring to its place within the five borough city. Similarly, an address in Queens County might be tagged as within the city of \"Queens\", as within the city of \"New York\", or most commonly as within the \"city\" of a neighborhood such as \"Flushing\" or \"Elmhurst\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Zipcode to City Mapping**\n",
    "\n",
    "I explored these inconsistencies further by mapping out what city tags were matched to each zip code throughout the data. Before mapping cities to zip codes, I also cleaned the data for the inconsistencies previously noted. This way, I was able to explore what concepts of city were used throughout the data while also abstracting out the grammatical and stylistic inconsistencies in (5) and (6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pullcitiesforzip (osmfile):\n",
    "    cityzipmapping = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\": for tag in elem.iter(\"tag\"):\n",
    "            if tag.attrib[\"k\"] == \"addr:postcode\": \n",
    "                zipcode = tag.attrib[\"v\"]\n",
    "                cityzipmapping[zipcode]\n",
    "                \n",
    "                for tag in elem.iter(\"tag\"):\n",
    "                    if tag.attrib[\"k\"] == \"addr:city\":\n",
    "                        city = tag.attrib[\"v\"]\n",
    "                        city = cleancity(city)\n",
    "                        cityzipmapping[zipcode].add(city)\n",
    "                        \n",
    "    cityzipmapping = cleanzip(cityzipmapping)\n",
    "    return cityzipmapping\n",
    "\n",
    "def cleanzip (dictionary):\n",
    "    cleanzip = {}\n",
    "    for k,v in dictionary.items(): \n",
    "        newkey = correctzip(k)\n",
    "        if newkey in cleanzip:\n",
    "            if list (v) and list(v).pop() not in cleanzip[newkey]: \n",
    "                cleanzip[newkey].append(list(v))\n",
    "        else:\n",
    "            cleanzip[newkey] = (list(v))\n",
    "    return cleanzip\n",
    "\n",
    "def cleancity (city):\n",
    "    if city in citymapping:\n",
    "        city = citymapping[city]\n",
    "    return city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summarized results were as follows:\n",
    "\n",
    " - Following convention, Manhattan zip codes are listed under the city of \"New York\", most Brooklyn zip codes are listed under city the of \"Brooklyn\", most Queens zip codes are listed as cities under their specific neighborhood (ex. \"Elmhurst\", \"Forest Hills\" \"Woodside\" , etc).\n",
    " \n",
    "However:\n",
    "\n",
    "- Eleven zip codes ('10275', '10281', '11104', '11228', '11251', '11367', '11415', '11418', '11419', '11420', '11697') in the data have no city tagged anywhere throughout the data.\n",
    "- Ten zip codes within Brooklyn ('11201', '11206', '11211', \"11215, '11216', '11219', '11233', '11237', '11238', '11249') also contain elements in which \"New York\" or some variation thereof is tagged as the city.\n",
    "- One Brooklyn zip code ('11203') also contains 'Waterbury' as its city. The closest \"Waterbury\" is in Connecticut so this tag is an obvious error.\n",
    "- One zip code ('71877') tagged as within \"Brooklyn\" is actually a phone number.\n",
    "- Five zip codes within Queens ('11373', '11374', '11375', '11377', '11385') also contain elements in which the city is given as either \"Queens\", \"New York\" or some variation therefore rather than the specific neighborhood.\n",
    "- Of these Five, two zip codes in Queens ('11374', '11385') are also respectively listed as within the city of 'Rego Park'/ 'Forest Hills' / 'Flushing' and 'Glendale'/'Ridgewood' depending upon the user.\n",
    "\n",
    "\n",
    "Drawing from these results, I created a new zip-code-to-city mapping that can be used to standardize this relationship within the data. This was done through the following steps\n",
    "- Drawing upon [zipcodestogo](http://www.zipcodestogo.com/New%20York/) as a resource, I updated the mapping to include cities for the eleven zip codes missing a value within the osm file .\n",
    "- Deleted 'New York' as a city from the 10 Brooklyn zip codes where this was included.\n",
    "- Change zip code '11215' to refer to 'Brooklyn' rather than \"New York.\n",
    "- Deleted 'Waterbury' from the '11203' zip code\n",
    "- Deleted \"Queens\" and \"New York\" from the 5 zip codes in Queens County which included a city tagged under this name.\n",
    "- Deleted \"Forest Hills\" and \"Flushing\" as cities from 11374. Only \"Rego Park\" should be included within this zip code\n",
    "[source](http://www.zipmap.net/zips/11374.htm)\n",
    "- After researching the [controversy](https://www.dnainfo.com/new-york/20141016/glendale/glendale-wants-its-own-zip-code-break-away-from-ridgewood) regarding the '11385' zip code, I choose to admit an exception within the data so that the city in this zip code can be either \"Ridgewood\", \"Glendale\", or be left empty.\n",
    "\n",
    "\n",
    "Using this zip-code-to-city mapping, I was also able to update all elements in the data that include a zip code but are missing a city. By running the code below I was able to determine there were 377,092 examples of missing cities that could be updated through this procedure. (Versus only 3,110 elements that have both city and zip code values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit (osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    count_city_listed = 0\n",
    "    count_city_not_listed = 0\n",
    "    other = 0\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            taglist = []\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                taglist.append(tag.attrib[\"k\"])\n",
    "            if \"addr:postcode\" in taglist and \"addr:city\" not in taglist:\n",
    "                count_city_not_listed += 1\n",
    "            elif \"addr:postcode\" in taglist and \"addr:city\" in taglist:\n",
    "                count_city_listed += 1 \n",
    "            else:\n",
    "                other +=1\n",
    "                \n",
    "    return (count_city_listed, count_city_not_listed, other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After updating the file for these missing cities, we can run a search in the SQL database for the top five cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cursor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cca48528e001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m cursor.execute ('''SELECT tags.value, COUNT(*) as count\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mFROM\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSELECT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFROM\u001b[0m \u001b[0mnodes_tags\u001b[0m \u001b[0mUNION\u001b[0m \u001b[0mALL\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFROM\u001b[0m \u001b[0mways_tags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtags\u001b[0m \u001b[0mWHERE\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"city\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGROUP\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ORDER BY count DESC;''')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cursor' is not defined"
     ]
    }
   ],
   "source": [
    "cursor.execute ('''SELECT tags.value, COUNT(*) as count\n",
    "FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) tags WHERE tags.key = \"city\"\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brooklyn,292375 <br>\n",
    "New York,17129 <br>\n",
    "Ozone Park,9708 <br>\n",
    "Middle Village,8714 <br>\n",
    "Maspeth,8137 <br>\n",
    "Forest Hills,77<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Additional Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The audit.py file is largely capable of cleaning the data for the inconsistencies in content and format noted in points 1 - 7. Perhaps most significantly, a zip code to city mapping was extracted from within the data, audited, and then applied back to the file to establish a more uniform relation between these values. When there are not widespread errors in the data, this methodology is perhaps the best suited for insuring the internal validity of a dataset.\n",
    "\n",
    "\n",
    "The limitation of this approach however is that it only tackles the relationships between the data points themselves, and cannot audit the relationship between the data and the \"outside\" world that such data is supposed to \"represent\". For datasets like the Openstreetmap Project, external accuracy, it seems to me, is largely dependent upon user-input and cannot be guaranteed by any data analysis alone. The role of the data analyst instead, might be to suggest where to begin looking for gaps between the data and the world.\n",
    "\n",
    "\n",
    "For example, many of the commercial tags are very outdated for a city that so rapidly developing as Brooklyn. A cursory query of the timestamps on \"restaurant\" tags returns the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SELECT nodes.timestamp FROM nodes JOIN nodes_tags ON nodes.id = nodes_ta\n",
    "gs.id WHERE nodes_tags.value = \"restaurant\" Limit 10;\n",
    "2014-10-17T07:11:55Z\n",
    "2009-07-25T20:35:59Z\n",
    "2016-04-18T14:12:28Z\n",
    "2012-06-28T18:29:26Z\n",
    "2010-01-21T16:32:22Z\n",
    "2010-01-21T16:32:21Z\n",
    "2010-01-21T16:32:21Z\n",
    "2010-01-21T16:32:21Z\n",
    "2010-01-21T16:36:14Z\n",
    "2010-01-21T16:36:14Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My suggestion for the future of the Openstreetmap Project is for data analysts to locate commercial blocks with timestamps that are, on average, over a certain number of years. Such blocks could be labeled as areas the most needing of user input. Since New Yorkers are generally excited to explore new commercial areas of the city, this classification might hopefully incentivize further user feedback.\n",
    "Although this approach respects the crowd-sourcing ethos of the Openstreetmap Project, one problem is that without a significant degree of user-diversification and participation, this commercial tagging project might not be inclusive of all areas of the city. In such case, requesting participation from governmental organizations such as NYC Department of Buildings or Department of Finance might be a more effective way of retrieving commercial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
